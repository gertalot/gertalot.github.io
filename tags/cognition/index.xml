<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cognition on Gert's blog</title><link>https://gertalot.com/tags/cognition/</link><description>Recent content in Cognition on Gert's blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 04 Dec 2025 01:43:47 +0000</lastBuildDate><atom:link href="https://gertalot.com/tags/cognition/index.xml" rel="self" type="application/rss+xml"/><item><title>LLMs don't think like humans</title><link>https://gertalot.com/posts/llms-dont-think-like-humans/</link><pubDate>Thu, 04 Dec 2025 01:43:47 +0000</pubDate><guid>https://gertalot.com/posts/llms-dont-think-like-humans/</guid><description>&lt;p&gt;In a conversation I had recently, someone suggested that our human thinking at some level is the same as LLM thinking.
I&amp;rsquo;ve thought about that a lot (over the past decades, given my degree in AI from many years ago), and it&amp;rsquo;s a really
interesting question: What actually separates human cognition from LLMs? Is there a fundamental difference between human
and machine intelligence?&lt;/p&gt;
&lt;p&gt;I think that there are, at least currently, a number of big differences between the way we think and the way LLMs think.&lt;/p&gt;</description></item></channel></rss>